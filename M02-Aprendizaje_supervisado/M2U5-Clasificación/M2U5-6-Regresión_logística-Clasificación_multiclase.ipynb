{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d9c6ef-79eb-4635-9509-2936e0720f69",
   "metadata": {},
   "source": [
    "# Regresión logística: Clasificación multiclase\n",
    "M2U5 - Ejercicio 6\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión logística multiclase\n",
    "- Preprocesar los datos\n",
    "- Entrenar el modelo sobre el subset de entrenamiento y comprobar su idoneidad\n",
    "- Hallar el parámetro de regularización *lambda* óptimo por CV\n",
    "- Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md).\n",
    "\n",
    "## Instrucciones\n",
    "Una vez implementado el entrenamiento completo de un modelo de regresión logística regularizada para clasificación binaria (2 clases), vamos a repetir el mismo ejemplo para clasificación multi-clase (3+ clases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b59c0-28c9-4d2d-a8a5-ae0009f3ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f11be-ac10-4360-b017-a42fcf07398c",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético para regresión logística multiclase\n",
    "\n",
    "Vamos a crear un dataset sintético de 3 clases para esta implementación completa.\n",
    "\n",
    "Para ello, crea un dataset sintético para regresión logística con término de bias y error de forma manual (para tener disponible *Theta_verd*) con una plantilla de código ligeramente diferente a la que has usado en el último ejercicio.\n",
    "\n",
    "Para la clasificación multiclase vamos a calcular la Y de una forma diferente: Y tendrá unas dimensiones 2D de (m x clases) para representar todas las clases posibles. A esta codificación de p. ej. [0, 0, 1] para la clase 3/3 la llamamos \"one-hot encoding\":\n",
    "\n",
    "- Para cada ejemplo y clase, calcula *Y* con el sigmoide con *Theta_verd* y *X*.\n",
    "- Transforma los valores de *Y* para que sean `0` o `1` según el valor máx. del sigmoide de todas las clases.\n",
    "- Por último, transforma en 1 el valor de la clase con un valor máx. del sigmoide, y en 0 los valores del resto de clases, con un ndarray final por cada ejemplo.\n",
    "\n",
    "Para introducir un término de error, recorre todos los valores de *Y* y, con un porcentaje de error aleatorio, modifica la clase de dicho ejemplo a una clase aleatoria.\n",
    "\n",
    "*NOTA:* Investiga cómo se podría conseguir un dataset sintético para clasificación multiclase con métodos de Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a9e47-7d6e-42be-afff-022e87606153",
   "metadata": {},
   "source": [
    "### Implementa la función de activación sigmoide\n",
    "\n",
    "Copia tu función de ejercicios anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f07fc-a338-48f7-970d-c68f0fd86cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa la función sigmoide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0394f2b-0bbe-411c-99b9-a6dbf31b266b",
   "metadata": {},
   "source": [
    "Crea el dataset sintético:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd3ee5d-0f0a-43d5-8055-94dbfa9fce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético con término de bias y error de forma manual\n",
    "# Ya que vamos a entrenar tantos modelos, generamos un dataset \"pequeño\" para que se entrenen rápido\n",
    "# Si lo necesitas, puedes hacerlo más pequeño aún, o si quieres más precisión y un reto más real, ampliarlo\n",
    "m = 1000\n",
    "n = 2\n",
    "clases = 3\n",
    "\n",
    "# Genera un array 2D m x n con valores aleatorios entre -1 y 1\n",
    "# Insértale el término de bias como una primera columna de 1s\n",
    "X = [...]\n",
    "\n",
    "# Genera un array de theta 2D de (clases x n + 1) valores aleatorios\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Y tendrá unas dimensiones 2D de (m x clases)\n",
    "# Calcula la Y con el sigmoide y transforma sus valores en 0 o 1 y luego a one-hot encoding\n",
    "for i in range(m):\n",
    "    for c in range(clases):\n",
    "        sigmoide_ejemplo = sigmoid([...])\n",
    "        # Asigna la única clase correspondiente al ejemplo según el valor máx. del sigmoide\n",
    "        Y[...] = [...]\n",
    "\n",
    "# Para introducir un término de error, recorre todos los valores de Y y, con un % de error aleatorio, modifica\n",
    "# la clase elegida de dicho ejemplo por otra clase aleatoria\n",
    "# Nota: asegúrate que la otra clase aleatoria que representa el error es diferente a la original\n",
    "error = 0.15\n",
    "\n",
    "for j in range(m):\n",
    "    # Si un nº al azar es menor o igual que error\n",
    "    if [...]:\n",
    "        # Asigna una clase escogida aleatoriamente\n",
    "        Y[...] = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar:')\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d203bc-1c5c-4993-93fe-750697a7b9cd",
   "metadata": {},
   "source": [
    "## Preprocesar los datos\n",
    "\n",
    "Al igual que hacíamos para la regresión lineal, vamos a preprocesar los datos completamente, siguiendo los 3 pasos habituales:\n",
    "\n",
    "- Reordenarlos aleatoriamente.\n",
    "- Normalizarlos.\n",
    "- Dividirlos en subsets de entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c92dd-161b-4e9e-8f07-fc508137220e",
   "metadata": {},
   "source": [
    "### Reordenar el dataset aleatoriamente\n",
    "\n",
    "Reordena los datos del dataset *X* e *Y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fccf14-2ca5-41f7-afb0-ccd737d1ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Reordena aleatoriamente el dataset\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Reordenamos X e Y:')\n",
    "# Usa un estado aleatorio inicial de 42, para mantener la reproducibilidad\n",
    "X, Y = [...]\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468764a7-e182-4026-aa89-4ae068b5c4ec",
   "metadata": {},
   "source": [
    "### Normalizar el dataset\n",
    "\n",
    "Implementa la función de normalización y normaliza el dataset de ejemplos *X*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecec13-4a02-48ef-8907-59a8b8c0ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset con una función de normalización\n",
    "\n",
    "# Copia tu función de normalización utilizada en la unidad de regresión lineal\n",
    "def normalize(x, mu, std):\n",
    "    pass\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657316f-9a8a-40cc-9551-fb6945acc02c",
   "metadata": {},
   "source": [
    "*Nota*: Si habías modificado tu función *normalize* para que calculara y devolviera los valores de *mu* y *std*, puedes modificar esta celda para incluir tu código personalizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdd699-3d04-4018-b485-de77e3f7d277",
   "metadata": {},
   "source": [
    "### Dividir el dataset en subsets de entrenamiento, validación y test\n",
    "\n",
    "Divide el dataset de *X* e *Y* en 3 subsets con el ratio habitual, 60%/20%/20%.\n",
    "\n",
    "Si tu nº de ejemplos es mucho más alto o bajo, siempre puedes modificar este ratio por otro como 50/25/25 o 80/10/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5743ce5-b995-4c15-8879-0f044a3e77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Divide el dataset X e Y en los 3 subsets según los ratios indicados\n",
    "\n",
    "ratio = [60, 20, 20]\n",
    "print('Ratio:\\n', ratio, ratio[0] + ratio[1] + ratio[2])\n",
    "\n",
    "r = [0, 0]\n",
    "# Consejo: la función round() y el atributo x.shape pueden serte útiles\n",
    "r[0] = [...]\n",
    "r[1] = [...]\n",
    "print('Índices de corte:\\n', r)\n",
    "\n",
    "# Consejo: la función np.array_split() puede serte útil\n",
    "X_train, X_val, X_test = [...]\n",
    "Y_train, Y_val, Y_test = [...]\n",
    "\n",
    "print('Tamaños de los subsets:')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12561eea-36a8-4089-a48e-3a4581772b73",
   "metadata": {},
   "source": [
    "## Entrenar un modelo inicial para cada clase\n",
    "\n",
    "Para la clasificación multiclase, debemos entrenar un modelo diferente para cada clase. Por tanto, si tenemos 3 clases debemos entrenar 3 modelos diferentes.\n",
    "\n",
    "Cada modelo sólo considerará los valores de la variable objetivo relativos a su clase de una forma binaria, clasificando los ejemplos como pertenecientes a su clase o no.\n",
    "\n",
    "Para ello, sólo le proporcionaremos los valores de *Y* para dicha clase o columna. P. ej., para `Y = [[1, 0, 1], [0, 1, 0], [0, 0, 1]]`:\n",
    "- *Y* para el modelo 1: `[1, 0, 0]`\n",
    "- *Y* para el modelo 2: `[0, 1, 0]`\n",
    "- *Y* para el modelo 3: `[0, 0, 1]`\n",
    "\n",
    "Al igual que hacíamos en ejercicios anteriores, vamos a entrenar modelos iniciales para comprobar que nuestra implementación es correcta:\n",
    "- Entrena un modelo inicial sin regularización para cada clase.\n",
    "- Representa el histórico de la función de coste para comprobar su evolución para cada modelo.\n",
    "- Si es necesario, modifica cualquier hiper-parámetro, como el ratio de entrenamiento, y reentrena los modelos. Usarás dichos hiper-parámetros en siguientes puntos.\n",
    "\n",
    "Copia las celdas de ejercicios anteriores donde implementabas la función de coste y gradient descent regularizados para regresión logística y la celda donde entrenabas el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545782d-7cc8-467e-8adf-18941068fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia las celdas con las funciones de coste y gradient descent para clasificación regularizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650cd71-3b18-4490-802e-22a8dc645261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tus modelos sobre el subset de entrenamiento sin regularizar\n",
    "\n",
    "# Crea una theta inicial con un valor dado, que puede ser el mismo para todos los modelos o no\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = 0.\n",
    "e = 1e-3\n",
    "iter_ = 1e3\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "# Inicializa unas variables para almacenar el resultado de cada modelo con las dimensiones adecuadas\n",
    "# Cuidado: los modelos pueden necesitar un nº de iteraciones hasta que convergen diferente\n",
    "# Dale a j_train un tamaño para almacenar hasta el nº máx. de iteraciones, aunque no se rellenen todos los elementos\n",
    "j_train_ini = [...]\n",
    "theta_train = [...]\n",
    "\n",
    "t = time.time()\n",
    "for c in [...]:    # Itera sobre el nº de clases\n",
    "    print('\\nModelo para la clase nº:', c)\n",
    "    \n",
    "    theta_train = [...]    # Copia profunda de theta_ini para que no se modifique\n",
    "    \n",
    "    t_model = time.time()\n",
    "    j_train_ini[...], theta_train[...] = regularized_logistic_gradient_descent([...])\n",
    "    \n",
    "    print('Tiempo de entrenamiento para el modelo (s):', time.time() - t_model)\n",
    "    \n",
    "print('Tiempo de entrenamiento total (s):', time.time() - t)\n",
    "\n",
    "print('\\nCoste final del modelo para cada clase:')\n",
    "print()\n",
    "\n",
    "print('\\nTheta final del modelo para cada clase:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a976f61e-0957-4b58-942c-e48a6d65cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones para cada modelo\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Función de coste en cada clase')\n",
    "\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('Coste clase {}'.format(c))\n",
    "    plt.plot(j_train_ini[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee15b79-9f67-4c69-8aed-451f5f69551b",
   "metadata": {},
   "source": [
    "### Comprobar la idoneidad de los modelos\n",
    "\n",
    "Revisa la precisión de tus modelos y modifica los parámetros para reentrenarlos si es necesario.\n",
    "\n",
    "Recuerda que si tu dataset es \"demasiado preciso\" puedes volver a la celda original e introducir un término de error superior.\n",
    "\n",
    "Por complejidad de una clasificación multiclase, no te pediremos en esta ocasión que compruebes si los modelos pueden estar sufriendo desviación o sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd6a11-0929-48e5-8d35-240a019d0923",
   "metadata": {},
   "source": [
    "## Hallar el hiper-parámetro *lambda* óptimo por validación\n",
    "\n",
    "Del mismo modo que hemos hecho en ejercicios anteriores, vamos a optimizar nuestro parámetro de regularización por validación para cada una de las clases y modelos.\n",
    "\n",
    "Para ello, para cada clase, vamos a entrenar un modelo diferente por cada valor de *lambda* a considerar sobre el subset de entrenamiento, y evaluar su error o coste final sobre el subset de validación.\n",
    "\n",
    "De nuevo, vamos a representar gráficamente el error de cada modelo vs el valor de *lambda* usado e implementar un código que elija automáticamente el modelo más óptimo de entre todos para cada clase.\n",
    "\n",
    "Recuerda entrenar todos tus modelos en igualdad de condiciones, con los mismos hiper-parámetros.\n",
    "\n",
    "Por tanto, ahora debes modificar el código de la celda anterior para no entrenar un modelo como antes sino uno por clase y por cada uno de los valores de *lambda* a considerar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fab78-1942-43b8-aa3c-2f202bd5d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo por cada valor de lambda diferente sobre X_train y evalúalo sobre X_val\n",
    "\n",
    "# Usa de nuevo un espacio logarítmico entre 10 y 10^3 de 5 elementos con valores que comiencen por un decimal no-cero 1 o 3\n",
    "# Al entrenar más modelos, podemos evaluar menos valores de lambda para reducir el tiempo de entrenamiento\n",
    "lambdas = [...]\n",
    "\n",
    "# Completa el código para entrenar un modelo diferente para cada clase y valor de lambda sobre X_train\n",
    "# Almacena sus thetas y costes finales\n",
    "# Posteriormente, evalúa sus costes totales en el subset de validación\n",
    "\n",
    "# Almacena dicha información en los siguientes arrays\n",
    "# Cuidado con sus dimensiones necesarias\n",
    "j_train = [...]\n",
    "j_val = [...]\n",
    "theta_val = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db658f-cf0b-4271-b93f-3c3835dce70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente el error final para cada valor de lambda con una gráfica por clase\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Completa con tu código\n",
    "for c in range(clases):\n",
    "    plt.subplot(clases, 1, c + 1)\n",
    "    \n",
    "    plt.title('Clase:', c)\n",
    "    plt.xlabel('Lambda')\n",
    "    plt.ylabel('Coste final')\n",
    "    plt.plot(j_train[...])\n",
    "    plt.plot(j_val[...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d6b5b5-5288-472f-83f5-fe0b5191a358",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo para cada clase\n",
    "\n",
    "Copia el código de ejercicios anteriores y modifícalo para escoger el modelo con mayor precisión sobre el subset de validación para cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288db2e0-2697-4569-ab34-68baf0606efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Escoge los modelos y valores de lambda óptimos, con el menor error sobre el subset de validación\n",
    "\n",
    "# Itera sobre todas las combinaciones de theta y lambda y escoge los modelos de menor coste en el subset de validación para cada clase\n",
    "\n",
    "j_final = [...]\n",
    "theta_final = [...]\n",
    "lambda_final = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71f987-c768-4668-928b-d83783d238a7",
   "metadata": {},
   "source": [
    "## Evaluar los modelos sobre el subset de test\n",
    "\n",
    "Finalmente, vamos a evaluar el modelo de cada clase sobre un subset de datos que no hemos usado para entrenarlos ni para escoger ningún hiper-parámetro.\n",
    "\n",
    "Para ello, vamos a calcular el coste o error total sobre el subset de test y comprobar gráficamente los residuos sobre el mismo.\n",
    "\n",
    "Recuerda usar sólo las columnas de la *Y* que \"vería\" cada modelo, puesto que clasifica los ejemplos en función de si pertenecen a su clase o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a255d-2ab8-4f10-8a5e-ff2928ee9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula el error de los modelos sobre el subset de test usando la función de coste\n",
    "# Utiliza la theta y lambda del modelo específico de la clase correspondiente a dicho ejemplo\n",
    "\n",
    "j_test = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c9941-fe87-4f09-9ecd-4a3536f48cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones de los modelos sobre el subset de test, calcula los residuos y represéntalos\n",
    "\n",
    "# Recuerda usar la función sigmoide para transformar las predicciones y escoger la clase según el valor máx. del sigmoide\n",
    "Y_test_pred = [...]\n",
    "\n",
    "residuos = [...]\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "# Completa con tu código\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095fd04-6f43-4a4b-9c63-9af9d9455114",
   "metadata": {},
   "source": [
    "## Realizar predicciones sobre nuevos ejemplos\n",
    "\n",
    "Con nuestros modelos ya entrenados, optimizados y evaluados, lo único que nos queda es utilizarlos realizando predicciones con nuevos ejemplos.\n",
    "\n",
    "Para ello, vamos a:\n",
    "- Generar un nuevo ejemplo, siguiendo el mismo patrón que el dataset original.\n",
    "- Normalizar sus características antes de poder realizar predicciones sobre ellos.\n",
    "- Generar una predicción para dicho nuevo ejemplo para cada una de las clases, para cada uno de los 3 modelos.\n",
    "- Escoger la clase final como la clase con mayor valor de *Y* tras el sigmoide, aunque varios modelos predijeran `Y >= 0.0; Y = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e3488-0e99-4479-9807-fd584a025eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo ejemplo siguiendo el patrón original, con término de bias\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "# Para comparar, antes de normalizar los datos, usa la Theta_verd para ver cuál sería la clase real asociada\n",
    "Y_verd = [...]\n",
    "\n",
    "# Normaliza sus características (excepto el término de bias) con las medias y desviaciones típicas del subset de entrenamiento\n",
    "X_pred = [...]\n",
    "\n",
    "# Genera una predicción para dicho ejemplo para cada modelo usando el sigmoide\n",
    "Y_pred = [...]\n",
    "\n",
    "# Escoge la clase final como la de mayor valor tras el sigmoide y transfórmala a un vector one-hot encoding de 0 y 1\n",
    "Y_pred = [...]\n",
    "\n",
    "# Compara la clase real asociada a dicho nuevo ejemplo y la clase predicha\n",
    "print('Clase real del nuevo ejemplo y clase predicha:')\n",
    "print(Y_verd)\n",
    "print(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
