{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd78b6e-f0b2-463d-a0fc-3cb7028b8fae",
   "metadata": {},
   "source": [
    "# Regresión lineal: Normalización\n",
    "M2U3 - Ejercicio 1\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético con características en diferentes rangos de valores\n",
    "- Entrenar un modelo de regresión lineal sobre el dataset original\n",
    "- Normalizar el dataset original\n",
    "- Entrenar otro modelo de regresión lineal sobre el dataset normalizado\n",
    "- Comparar el entrenamiento de ambos modelos, normalizado y no normalizado\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08edc5e4-f421-43a6-bc2a-81b519b3d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d98df0-1c0f-4d3a-96fa-421c510fbc48",
   "metadata": {},
   "source": [
    "## Creación del dataset sintético\n",
    "\n",
    "Vamos a crear de nuevo un dataset sintético para regresión lineal por el método manual.\n",
    "\n",
    "Crea un dataset sintético con un término de error del 10% del valor sobre *Y* y una *X* en apróx. el rango (-1, 1), en esta ocasión de forma manual, no con los métodos específicos de Scikit-learn, con el código utilizado en ejercicios previos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852d3d6-6ab9-4eea-b570-f46e578e5430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia el código de ejercicios anteriores para generar un dataset con término de bias y error\n",
    "\n",
    "m = 1000\n",
    "n = 4\n",
    "\n",
    "X = [...]\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.1\n",
    "\n",
    "Y = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ce2dc-fb9c-48d8-b8e2-b467a6b34888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2797d-f580-4ad5-8eb9-ec8dbe307a8d",
   "metadata": {},
   "source": [
    "Ahora vamos a modificar el dataset para asegurarnos de que cada característica, cada columna de *X*, tiene un órden de magnitud y una media diferente.\n",
    "\n",
    "Para ello, multiplica cada columna de *X* (excepto la primera, el bias, que debe ser todo 1.) por un rango diferente y súmale un valor de bias diferente.\n",
    "\n",
    "El valor que sumamos luego resultará la media de dicha característica o columna, y el valor por el que multliplicamos su rango o escala.\n",
    "\n",
    "P. ej., $X_1 = X_1 * 10^3 + 3.1415926$, donde `10^3` será la media y `3,1415926` la escala de la característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838c8d9-b6c7-4372-8ee5-d204d02d67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Para cada columna de X, multiplícala por un rango de valores y súmale una media diferente\n",
    "\n",
    "# Los arrays de rangos y medias tienen que ser de longitud n\n",
    "# Crea un array con los rangos de valores, p. ej.: 1e0, 1e3, 1e-2, 1e5\n",
    "rangos = [...]\n",
    "\n",
    "medias = [...]\n",
    "\n",
    "X = [...]\n",
    "\n",
    "print('X con medias y escalas diferentes')\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231cbb2-6163-4d66-98f6-388a59c08761",
   "metadata": {},
   "source": [
    "Recuerda que puedes ejecutar celdas de Jupyter en un orden distinto a su posición en el documento. Los corchetes a la izquierda de las celdas marcarán el órden de ejecución, y las variables mantendrán en todo momento sus valores tras la última celda ejecutada, **¡cuidado!**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1620b3-2c86-49f6-a244-af617f1acd6b",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo\n",
    "\n",
    "Vamos a volver a entrenar un modelo de regresión lineal. En esta ocasión, vamos a entrenarlo primero sobre el dataset original, sin normalizar, y luego reentrenarlo sobre el dataset ya normalizado, para comparar ambos modelos y procesos de entrenamiento y ver los efectos de la normalización.\n",
    "\n",
    "Para ello debes copiar las celdas o el código de ejercicios anteriores y entrenar un modelo de regresión lineal multivariable, optimizado por gradient descent, sobre el dataset original.\n",
    "\n",
    "También debes copiar las celdas que comprueban el entrenamiento del modelo, representando la función de coste vs el nº de iteraciones.\n",
    "\n",
    "No es necesario que hagas predicciones sobre estos datos ni evalues los residuos del modelo. Para compararlos, lo haremos únicamente a través del coste final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed296163-cc10-42b6-9b94-ff5d661891f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de regresión lineal y representa gráficamente la evolución de su función de coste\n",
    "# Usa la X no normalizada\n",
    "# Añádele el sufijo \"_no_norm\" a las variables Theta y j_hist que devuelve tu modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a01c7-aa0e-46ad-85fe-0c95f9513732",
   "metadata": {},
   "source": [
    "## Normalización de los datos\n",
    "\n",
    "Vamos a normalizar los datos del dataset original.\n",
    "\n",
    "Para ello, vamos a crear una función de normalización que aplique la transformación necesaria, según la fórmula:\n",
    "\n",
    "$x_j = \\frac{x_j - \\mu_{j}}{\\sigma_{j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29339c02-1f97-44bc-b6b9-b8fe446c6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementa una función de normalización a un rango común y con media 0\n",
    "\n",
    "def normalize(x, mu, std):\n",
    "    \"\"\" Normaliza un dataset con ejemplos X\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los ejemplos, sin término de bias\n",
    "    mu -- vector 1D de Numpy con la media de cada característica/columna\n",
    "    std -- vector 1D de Numpy con la desviación típica de cada característica/columna\n",
    "    \n",
    "    Devuelve:\n",
    "    x_norm -- array 2D de Numpy con los ejemplos, con sus características normalizadas\n",
    "    \"\"\"\n",
    "    return [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4bb8d-62ad-4a82-94fc-b653dbdce5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza el dataset original usando tu función de normalización\n",
    "\n",
    "# Halla la media y la desviación típica de las características de X (columnas), excepto la primera (bias)\n",
    "mu = [...]\n",
    "std = [...]\n",
    "\n",
    "print('X original:')\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print('Media y desviación típica de las características:')\n",
    "print(mu)\n",
    "print(mu.shape)\n",
    "print(std)\n",
    "print(std.shape)\n",
    "\n",
    "print('X normalizada:')\n",
    "X_norm = np.copy(X)\n",
    "X_norm[...] = normalize(X[...], mu, std)    # Normaliza sólo la columna 1 y siguientes, no la 0\n",
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a478df-2bfe-44d0-a8dd-9803bc10d7d2",
   "metadata": {},
   "source": [
    "*BONUS:*\n",
    "1. Calcula las medias y desviaciones típicas de *X_norm* según sus características/columnas.\n",
    "1. Compáralas con las de *X*, *mu* y *std*\n",
    "1. Representa en una comparativa las distribuciones de *X* y *X_norm* con una gráfica de barras o box plot (puedes usar múltiples subplots de Matplotlib)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2282464-871d-4f5a-b37d-1fddc565deab",
   "metadata": {},
   "source": [
    "## Reentrenamiento del modelo y comparación de resultados\n",
    "\n",
    "Ahora reentrena el modelo sobre el dataset normalizado. Comprueba el coste final y la iteración en la que ha convergido.\n",
    "\n",
    "Para ello, puedes volver a las celdas de entrenar el modelo y comprobar la evolución de la función de coste y modificar la *X* utilizada por *X_norm*.\n",
    "\n",
    "En muchos casos, al ser un modelo tan simple, puede que no se aprecie ninguna mejora. En función de la capacidad de tu entorno de trabajo, prueba a utilizar un nº mayor de características y en aumentar ligeramente el término de error del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504bb63c-dab8-4ef1-9290-ec401dd48e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena un modelo de regresión lineal y representa gráficamente la evolución de su función de coste\n",
    "# Usa la X normalizada\n",
    "# Añádele el sufijo \"_norm\" a las variables Theta y j_hist que devuelve tu modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7ab5a-96a6-4cfd-965e-87cb06074c57",
   "metadata": {},
   "source": [
    "*PREGUNTA: ¿Ha habido diferencias en la precisión y tiempo de entrenamiento entre el modelo sobre datos no normalizados y el modelo sobre datos normalizados? Si incrementas el término de error y la diferencia de medias y rangos entre las características, ¿se aprecia mayor diferencia?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db510f96-5b5a-405c-9b18-53335a1380d7",
   "metadata": {},
   "source": [
    "## Cuidado con la Theta original\n",
    "\n",
    "Para el dataset original, antes de normalizarlo, se cumplía la relación $Y = X \\times \\Theta$.\n",
    "\n",
    "Sin embargo, ahora hemos modificado la *X* de dicha función.\n",
    "\n",
    "Por tanto, comprueba qué sucede si quieres volver a computar la *Y* usando la *X* normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c9276-898b-4075-8f85-14a6433a08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba si hay diferencias entre la Y original y la Y usando la X normalizada\n",
    "\n",
    "# Comprueba el valor de Y al multiplicar X_norm y Theta_verd\n",
    "Y_norm = [...]\n",
    "\n",
    "# Comprueba si hay diferencias entre Y_norm e Y\n",
    "diff = Y_norm - Y\n",
    "\n",
    "print('Diferencias entre Y_norm e Y (primeras 10 filas):')\n",
    "print(diff[:10])\n",
    "\n",
    "# Representa en un gráfico de puntos la diferencia entre Ys vs X\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7eb8f-449c-4314-a6e0-a2c96da46f05",
   "metadata": {},
   "source": [
    "### Realizar predicciones\n",
    "\n",
    "Del mismo modo, ¿qué sucede cuando vamos a utilizar el modelo para realizar predicciones?\n",
    "\n",
    "Genera un nuevo conjunto de datos *X_pred* siguiendo el mismo método que usaste para el dataset *X* original, incorporando el término de bias, multiplicando sus características por un rango y sumándoles valores diferentes, sin normalizarlo finalmente.\n",
    "\n",
    "También calcula su *Y_pred_verd* (sin término de error), como valor verdadero de *Y* a intentar predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58266bfc-775e-4b71-968d-efec6049e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un nuevo dataset de menor nº de ejemplos e igual nº de características que el dataset original\n",
    "# Asegúrate de que tiene una media o rango normalizado entre características/columnas\n",
    "\n",
    "X_pred = [...]\n",
    "\n",
    "Y_pred_verd = np.matmul(X_pred, Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5c7760-e745-4c87-9f65-d38379bd1c69",
   "metadata": {},
   "source": [
    "Ahora comprueba si habría alguna diferencia entre la *Y_pred_verd* y la *Y_pred* que predeciría tu modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfa630-2986-48a8-98a7-1e5c2397b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba las diferencias entre la Y real y la Y predicha\n",
    "\n",
    "Y_pred = np.matmul(X_pred, theta)\n",
    "\n",
    "diff = Y_pred_verd - Y_pred\n",
    "\n",
    "print('Diferencias entre la Y real y la Y predicha:')\n",
    "print(diff[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982753d9-e862-44a1-b7f1-9ed679b30e77",
   "metadata": {},
   "source": [
    "Dado que las predicciones no son correctas sino, deberíamos previamente normalizar la nueva *X_pred* antes de generar las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb3bc9-8049-4c83-ac44-b745617db797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Normaliza la X_pred\n",
    "\n",
    "X_pred[...] = normalize(X_pred[...], mu, std)\n",
    "\n",
    "print(X_pred[:10,:])\n",
    "print(X_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2adea-14ff-45bf-ac88-bb684a598abd",
   "metadata": {},
   "source": [
    "En esta ocasión no hemos generado una nueva variable diferente al normalizar, sino que sigue siendo la variable *X_pred*.\n",
    "\n",
    "Así puedes reejecutar la celda anterior para, ahora que *X_pred* está normalizada, comprobar si hay alguna diferencia entre la *Y* real y la *Y* predicha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94370b2-64ca-4445-8405-804216ebfd0b",
   "metadata": {},
   "source": [
    "Por tanto, recuerda siempre:\n",
    "- La *theta* calculada al entrenar el modelo será relativa siempre al dataset normalizado, y no se podrá usar para el dataset original, ya que a igual *Y* y distinta *X*, *Theta* debe cambiar.\n",
    "- Para hacer predicciones sobre nuevos ejemplos, antes tenemos que normalizarlos también, usando los mismos valores de medias y desviaciones típicas que usamos originalmente para entrenar el modelo."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
