{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3064ed2b-d40e-4c47-92be-8f482d0894a1",
   "metadata": {},
   "source": [
    "# Regresión lineal: Comparación de valores de regularización\n",
    "M2U3 - Ejercicio 3\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Crear un dataset sintético para regresión lineal multivariable con un término de error aleatorio\n",
    "- Entrenar 3 modelos de regresión lineal diferentes sobre dicho dataset con diferentes valores de *lambda*\n",
    "- Comparar el efecto del valor de *lambda* sobre el modelo, su precisión y sus residuos\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a0c848-4a74-4625-81f8-16026ae359fd",
   "metadata": {},
   "source": [
    "## Crear un dataset sintético con error para entrenamiento y test final\n",
    "\n",
    "Vamos a comenzar, como siempre, creando un dataset sintético para regresión lineal, con términos de bias y de error, de forma manual o con los métodos de Scikit-learn.\n",
    "\n",
    "En esta ocasión vamos a crear 2 datasets, uno para entrenamiento y otro para test final, siguiendo el mismo patrón aunque con tamaños diferentes. Vamos a entrenar los modelos con el primer dataset y comprobar posteriormente con el segundo cómo se comportarían ante datos que no han \"visto\" previamente en el proceso de entrenamiento, que son completamente nuevos para ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e16d5-eb44-448a-9173-fc54c9abd89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintéitico manualmente, con término de bias y término de error\n",
    "\n",
    "m = 100\n",
    "n = 1\n",
    "\n",
    "X_train = [...]\n",
    "X_test = [...]    # El tamaño del dataset de test debe ser un 25% del original\n",
    "\n",
    "Theta_verd = [...]\n",
    "\n",
    "error = 0.35\n",
    "\n",
    "Y_train = [...]\n",
    "Y_test = [...]\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Comprueba X_train, X_test, Y_train e Y_test\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6289d719-6d79-4078-a8e9-e1e45071b25c",
   "metadata": {},
   "source": [
    "## Entrenar 3 modelos diferentes con diferentes valores de *lambda*\n",
    "\n",
    "Ahora vamos a entrenar 3 modelos diferentes con diferentes valores de *lambda*.\n",
    "\n",
    "Para ello, comienza por copiar tus celdas con el código que implementa la función de coste y el gradient descent regularizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fcd813-f806-4750-bdc9-d76be0e5d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia aquí las celdas o el código para implementar 2 funciones con la función de coste y el gradient\n",
    "# descent regularizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff72fa1-6b3f-4ee8-a5ed-6437c7fb595a",
   "metadata": {},
   "source": [
    "Vamos a entrenar los modelos. Para ello, recuerda que con Jupyter puedes simplemente modificar las celdas de código y las variables quedarán en la memoria del kernel de Jupyter.\n",
    "\n",
    "Por tanto, puedes p. ej. modificar el nombre de las siguientes variables, cambiando \"1\" por \"2\" y \"3\", y simplemente reejecutar la celda para almacenar los resultados de los 3 modelos, mientras que las variables de anteriores modelos siguen estando disponibles.\n",
    "\n",
    "Si te encuentras con alguna dificultad, también puedes copiar varias veces la celda de código y tener 3 celdas para entrenar a 3 modelos con nombres de variables diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e952b-eb2b-473e-9afb-120b18b005eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba tu implementación entrenando un modelo sobre el dataset sintético creado previamente\n",
    "\n",
    "# Crea una theta inicial con un valor constante dado (por esta vez, no de forma aleatoria).\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "lambda_ = [1e-3, 1e-1, 1e1]    # Usaremos 3 valores diferentes\n",
    "e = 1e-3\n",
    "iter_ = 1e3    # Comprueba que tu función puede admitir valores float o modifícalo\n",
    "\n",
    "print('Hiper-arámetros usados:')\n",
    "print('Alpha:', alpha, 'Error máx.:', e, 'Nº iter', iter_)\n",
    "\n",
    "t = time.time()\n",
    "# Usa lambda_[i], con i en el rango [0, 1, 2] para cada modelo\n",
    "j_hist_1, theta_final_1 = gradient_descent([...])\n",
    "\n",
    "print('Tiempo de entrenamiento (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores de la función de coste')\n",
    "print(j_hist_1[...])\n",
    "print('\\Coste final:')\n",
    "print(j_hist_1[...])\n",
    "print('\\nTheta final:')\n",
    "print(theta_final_1)\n",
    "\n",
    "print('Valores verdaderos de Theta y diferencia con valores entrenados:')\n",
    "print(Theta_verd)\n",
    "print(theta_final_1 - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f32f2d-32ac-4b58-954a-f1e3aec73aa8",
   "metadata": {},
   "source": [
    "## Comprobar gráficamente el efecto de *lambda* sobre los modelos\n",
    "\n",
    "Ahora vamos a comprobar los 3 modelos entre sí.\n",
    "\n",
    "Vamos a comenzar por comprobar el coste final, una representación de la precisión de los mismos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c7326-96ee-4d20-b2d8-a4f3042e0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Muestra el coste final de los 3 modelos:\n",
    "\n",
    "print('Coste final de los 3 modelos:')\n",
    "print(j_hist_1[...])\n",
    "print(j_hist_2[...])\n",
    "print(j_hist_3[...])\n",
    "\n",
    "# Representa visualmente el coste frente a los valores de lambda con un gráfico de líneas y puntos\n",
    "plt.plot([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef947036-e97c-4d1f-9270-b359c0077acd",
   "metadata": {},
   "source": [
    "*¿Cómo afecta un mayor valor de *lambda* al coste final en este dataset?*\n",
    "\n",
    "Vamos a representar los dataset de entrenamiento y test, para comprobar que siguen un patrón similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04402c0-858d-4285-ae96-b728e48ef7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa X_train vs Y_train y X_test vs Y_test gráficamente\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title([...])\n",
    "plt.xlabel([...])\n",
    "plt.ylabel([...])\n",
    "\n",
    "# Recuerda usar colores diferentes\n",
    "plt.scatter([...])\n",
    "plt.scatter([...])\n",
    "\n",
    "# Crea una leyenda para las diferentes series y sus colores\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ff5d0-e1b9-41b9-8701-b22c889209fb",
   "metadata": {},
   "source": [
    "Ahora vamos a comprobar las predicciones de cada modelo sobre el dataset de entrenamiento, para comprobar cómo se ajusta la recta a los valores de entrenamiento en cada caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab90ac-ce83-4e49-b3ed-1e604de010e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones para cada modelo sobre X_train\n",
    "\n",
    "Y_train_pred1 = [...]\n",
    "Y_train_pred2 = [...]\n",
    "Y_train_pred3 = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919048cf-dd27-476e-af86-2f403e77bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente para cada modelo sus predicciones sobre X_train\n",
    "\n",
    "# Si te da un error con otras gráficas del notebook, usa la línea inferior de plt.figure() o coméntala\n",
    "plt.figure(2)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "fig.suptitle([...])\n",
    "\n",
    "# Utiliza colores diferentes para cada modelo\n",
    "\n",
    "ax1.plot()\n",
    "ax1.scatter()\n",
    "\n",
    "ax2.plot()\n",
    "ax2.scatter()\n",
    "\n",
    "ax3.plot()\n",
    "ax3.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f424f3a-cbac-4f50-a51b-42369e76fb59",
   "metadata": {},
   "source": [
    "Al tener el dataset de entrenamiento un término de error, puede haber diferencias significativas entre los datos del dataset de entrenamiento y el dataset de test. Puedes jugar con varios valores de dicho término para aumentar o disminuir la diferencia.\n",
    "\n",
    "Vamos a comprobar qué ocurre con las predicciones cuando las representamos sobre el dataset de test, sobre datos que los modelos no han visto anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74c55b-d431-458e-aeb9-9acec635a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calcula las predicciones para cada modelo sobre X_test\n",
    "\n",
    "Y_test_pred1 = [...]\n",
    "Y_test_pred2 = [...]\n",
    "Y_test_pred3 = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f231a2-1c22-4fdf-8d3f-eee83d35fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente para cada modelo sus predicciones sobre X_test\n",
    "\n",
    "# Si te da un error con otras gráficas del notebook, usa la línea inferior de plt.figure() o coméntala\n",
    "plt.figure(3)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "fig.suptitle([...])\n",
    "\n",
    "# Utiliza colores diferentes para cada modelo\n",
    "\n",
    "ax1.plot()\n",
    "ax1.scatter()\n",
    "\n",
    "ax2.plot()\n",
    "ax2.scatter()\n",
    "\n",
    "ax3.plot()\n",
    "ax3.scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47348a65-925c-4009-8cc9-b3bee04e261d",
   "metadata": {},
   "source": [
    "¿Qué sucede? En algunos casos, en función de los parámetros utilizados puede que te sea más o menos fácil apreciarlo.\n",
    "\n",
    "Cuando el modelo tiene un factor de regulación *lambda* bajo o nulo, se ajusta demasiado a los datos con los que se entrena, consiguiendo una curva muy pegada y una precisión máxima... sólo sobre dicho dataset.\n",
    "\n",
    "Sin embargo, en la vida real, posteriormente pueden llegar datos sobre los que no hemos entrenado el modelo que tengan alguna pequeña variación sobre los datos originales.\n",
    "\n",
    "En dicha situación vamos a preferir un valor de *lambda* más alto, que nos permita tener una precisión mayor para los nuevos datos, aunque perdamos algo de precisión para los datos del dataset de entrenamiento.\n",
    "\n",
    "Por tanto, buscamos que un modelo \"generalice\" y pueda hacer buenas predicciones sobre nuevos datos, en lugar de que simplemente \"memorice\" los resultados que ya ha visto.\n",
    "\n",
    "Podemos por tanto pensar en la regularización como un alumno que tiene las preguntas del examen antes de presentarse:\n",
    "- Si luego le caen dichas preguntas, va a tener una nota (o precisión) muy alta, puesto que ya \"ha visto\" las preguntas previamente.\n",
    "- Si luego las preguntas son diferentes, puede tener una nota bastante alta, en función de lo similares que sean.\n",
    "- Sin embargo, si las preguntas son totalmente diferentes, va a tener una nota muy baja, porque no es que hubiera estudiado mucho la asignatura, sino que sus notas eran altas sólo por saber el resultado de antemano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec3f7fb-ef8e-41b5-bb52-59239dbdb0db",
   "metadata": {},
   "source": [
    "## Comprobar los residuos sobre el subset de test final\n",
    "\n",
    "Representa los residuos para los 3 modelos gráficamente. De esta forma vas a poder comparar tus 3 modelos sobre los 2 datasets.\n",
    "\n",
    "Calcúlalos tanto para el dataset de entrenamiento como para el de testing. Puedes hacerlo con celdas diferentes para poder apreciar sus diferencias a la vez.\n",
    "\n",
    "*Consejos*:\n",
    "- Cuidado con las escalas de los ejes X e Y a la hora de hacer las comparaciones.\n",
    "- Para poder verlos a la vez, puedes crear 3 subgráficas horizontales, en lugar de verticales, con \"plt.subplots(1, 3)\".\n",
    "- Utiliza colores diferentes para cada uno de los 3 modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c52d96-c5d4-40af-bed5-e6169479a2a6",
   "metadata": {},
   "source": [
    "Si no aprecias claramente dichos efectos sobre tus datasets, puedes probar a modificar los valores iniciales:\n",
    "- Con un nº de ejemplos *m* mayor, para que los modelos puedan ser más precisos.\n",
    "- Con un término de error mayor, para que haya más diferencia o variación entre ejemplos.\n",
    "- Con un tamaño del dataset de test sobre el de entrenamiento menor, para que haya más diferencias entre ambos datasets (al tener más datos, los valores pueden suavizarse más).\n",
    "- Etc."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
