{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9afd25-e3cb-4641-883a-a8e708e2a736",
   "metadata": {},
   "source": [
    "# Regresión lineal: Ejemplo sobre dataset sintético\n",
    "M2U2 - Ejercicio 5\n",
    "\n",
    "## ¿Qué vamos a hacer?\n",
    "- Usar un dataset sintético generado automáticamente para comprobar nuestra implementación\n",
    "- Entrenar un modelo de ML de regresión lineal multivariable\n",
    "- Comprobar la evolución del entrenamiento del modelo\n",
    "- Evaluar el modelo de una forma simple\n",
    "- Hacer predicciones sobre nuevos ejemplos futuros\n",
    "\n",
    "Recuerda seguir las instrucciones para las entregas de prácticas indicadas en [Instrucciones entregas](https://github.com/Tokio-School/Machine-Learning/blob/main/Instrucciones%20entregas.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8adcb2-aeae-4431-98d0-3f157acf9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12947e67-26b6-448d-9714-5bfa36be3250",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creación del dataset sintético\n",
    "\n",
    "Vamos a crear un dataset sintético para comprobar nuestra implementación.\n",
    "\n",
    "Según los métodos que hemos usado en ejercicios previos, crea un dataset sintético usando el método de Numpy.\n",
    "\n",
    "Incluye un término de error controlable en dicho dataset, pero inícialo a 0, puesto que para hacer la primera implementación de este modelo de ML de regresión lineal multivariable queremos que no haya ningún error en los datos que pueda esconder un error en nuestro modelo.\n",
    "\n",
    "Posteriormente introduciremos dicho término de error para comprobar que nuestra implementación también puede entrenar el modelo en estas circunstancias, más reales.\n",
    "\n",
    "### El término de bias o intercept\n",
    "\n",
    "En esta ocasión, vamos a generar el dataset sintético con una pequeña modificación: vamos a añadir una primera columna de 1s a X, o un 1. (float) como primer valor de las características de cada ejemplo.\n",
    "\n",
    "Además, puesto que añadimos una característica n más a la matriz X, añadimos una característica o valor más al vector $\\Theta$, contando pues con n + 1 características.\n",
    "\n",
    "¿Por qué añadimos esta columna, este nuevo término o característica?\n",
    "\n",
    "Porque es la forma más sencilla de implementar la ecuación lineal en una sóla operación de álgebra lineal, osea, vectorizada.\n",
    "\n",
    "De esta forma, convertimos pues $Y = m \\times X + b$ en $Y = X \\times \\Theta$, ahorrándonos una operación de suma e implementando la ecuación en una única operación de multiplicación matricial.\n",
    "\n",
    "El término *b*, por tanto, se incorpora como el primer término del vector $\\Theta$, que al multiplicar a la primera columna de X, siéndo ésta de valor 1 para todas las filas, nos permite añadir dicho término *b* a cada ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87898f6d-d055-47e1-a732-ba32515bcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Genera un dataset sintético, con término de error incialmente a 0, de la forma que escojas\n",
    "\n",
    "m = 100\n",
    "n = 3\n",
    "\n",
    "# Crea una matriz de nºs aleatorios en el intervalo [-1, 1)\n",
    "X = [...]\n",
    "# Inserta un vector de 1s como 1ª columna de X\n",
    "# Consejos: np.insert(), np.ones(), index 0, axis 1...\n",
    "X = [...]\n",
    "\n",
    "# Genera un vector de nºs aleatorios en el intervalo [0, 1) de tamaño n + 1 (al añadir el término bias)\n",
    "Theta_verd = [...]\n",
    "\n",
    "# Añade al vector Y un término de error aleatorio en % (0.1 = 10%) inicializado a 0\n",
    "# Dicho término representa un error en +/- dicho porcentaje, p. ej., +/- 5%, +/- 10%, etc., no sólo a sumar\n",
    "# El porcentaje de error se calcula sobre Y, por lo tanto el error sería p. ej. el +3,14% de Y, -4,12% de Y...\n",
    "error = 0.\n",
    "\n",
    "Y = np.matmul(X, Theta_verd)\n",
    "Y = Y + [...] * error\n",
    "\n",
    "# Comprueba los valores y dimensiones de los vectores\n",
    "print('Theta a estimar y sus dimensiones:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Primeras 10 filas y 5 columnas de X e Y:')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Dimensiones de X e Y:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea2b0c-65c3-44fe-bd4a-7893e439c4ee",
   "metadata": {},
   "source": [
    "Fíjate en la operación de multiplicación matricial implementada: $Y = X \\times \\Theta$\n",
    "\n",
    "Comprueba las dimensiones de cada vector: X, Y, $\\Theta$.\n",
    "*¿Crees que es una operación posible según las reglas del álgebra lineal?*\n",
    "\n",
    "Si tienes dudas, puedes consultar la documentación de Numpy relativa a la función np.matmul.\n",
    "\n",
    "Comprueba el resultado, tal vez reduciendo el nº de ejemplos y características original, y asegúrate de que es un resultado correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9c1d5-c55b-4738-b6e7-a311bb352715",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Copia del ejercicio anterior tu implementación de la función de coste y su optimización por gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a626cc6-67cb-477f-b624-0908ddd4bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copia el código de tus funciones de coste y descenso de gradiente\n",
    "\n",
    "def cost_function(x, y, theta):\n",
    "    \"\"\" Computa la función de coste para el dataset y coeficientes considerados.\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los valores de las variables independientes de los ejemplos, de tamaño m x n + 1\n",
    "    y -- array 1D de Numpy con la variable dependiente/objetivo, de tamaño m x 1\n",
    "    theta -- array 1D de Numpy con los pesos de los coeficientes del modelo, de tamaño 1 x n + 1(vector fila)\n",
    "    \n",
    "    Devuelve:\n",
    "    j -- float con el coste para dicho array theta\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, e, iter_):\n",
    "    \"\"\" Entrena el modelo optimizando su función de coste por gradient descent\n",
    "    \n",
    "    Argumentos posicionales:\n",
    "    x -- array 2D de Numpy con los valores de las variables independientes de los ejemplos, de tamaño m x n + 1\n",
    "    y -- array 1D de Numpy con la variable dependiente/objetivo, de tamaño m x 1\n",
    "    theta -- array 1D de Numpy con los pesos de los coeficientes del modelo, de tamaño 1 x n + 1 (vector fila)\n",
    "    alpha -- float, ratio de entrenamiento\n",
    "    \n",
    "    Argumentos nombrados (keyword):\n",
    "    e -- float, diferencia mínima entre iteraciones para declarar que el entrenamiento ha convergido finalmente\n",
    "    iter_ -- int/float, nº de iteraciones\n",
    "    \n",
    "    Devuelve:\n",
    "    j_hist -- list/array con la evolución de la función de coste durante el entrenamiento, de tamaño nº de iteraciones que ha usado el modelo\n",
    "    theta -- array de Numpy con el valor de theta en la última iteración, de tamaño 1 x n + 1\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b83ca-7bdb-42e6-9320-7a0f3eeec93c",
   "metadata": {},
   "source": [
    "Vamos a utilizar dichas funciones para entrenar nuestro modelo de ML.\n",
    "\n",
    "Recordamos los pasos que vamos a seguir:\n",
    "- Iniciar $\\Theta$ con valores aleatorios\n",
    "- Optimizar $\\Theta$ reduciendo el coste asociado a cada iteración de sus valores\n",
    "- Cuando hayamos encontrado el valor mínimo de la función de coste, tomar su $\\Theta$ asociada como los coeficientes de nuestro modelo\n",
    "\n",
    "Por tanto, completa el código de la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fdc77-da49-471a-b986-73be8ec6d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrena tu modelo de ML optimizando sus coeficientes Theta por gradient descent\n",
    "\n",
    "# Inicializa theta con n + 1 valores aleatorios\n",
    "theta_ini = [...]\n",
    "\n",
    "print('Theta inicial:')\n",
    "print(theta_ini)\n",
    "\n",
    "alpha = 1e-1\n",
    "e = 1e-4\n",
    "iter_ = 1e5\n",
    "\n",
    "print('Hiper-parámetros a utilizar:')\n",
    "print('Alpha: {}, e: {}, nº máx. iter: {}'.format(alpha, e, iter_))\n",
    "\n",
    "t = time.time()\n",
    "j_hist, theta = gradient_descent([...])\n",
    "\n",
    "print('Tiempo de entrenamiento (s):', time.time() - t)\n",
    "\n",
    "# TODO: completar\n",
    "print('\\nÚltimos 10 valores de la función de coste')\n",
    "print(j_hist[...])\n",
    "print('\\Coste final:')\n",
    "print(j_hist[...])\n",
    "print('\\nTheta final:')\n",
    "print(theta)\n",
    "\n",
    "print('Valores verdaderos de Theta y diferencia con valores entrenados:')\n",
    "print(Theta_verd)\n",
    "print(theta - Theta_verd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c814b-faf2-488b-add1-5448b5d3c793",
   "metadata": {},
   "source": [
    "Comprueba que no se ha modificado la $\\Theta$ inicial. Tu implementación debe copiar un nuevo objeto de Python en cada iteración y no modificarla durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df9748-858d-4ac8-b3b0-17140e921436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comprueba que no se ha modificado la Theta inicial\n",
    "\n",
    "print('Theta inicial y theta final:')\n",
    "print(theta_ini)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50ac66-c917-4e73-a6d1-c7216938e9f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comprobar el entrenamiento del modelo\n",
    "\n",
    "Para comprobar el entrenamiento del modelo, vamos a representar gráficamente la evolución de la función de coste, para comprobar que no ha habido ningún gran salto y que haya avanzado constantemente hacia un valor mínimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e993a2b-95ce-435e-a5e0-7aa5ab1ad898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa la evolución de la función de coste vs el nº de iteraciones\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "plt.title('Función de coste')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Coste')\n",
    "\n",
    "plt.plot([...])    # Completa los argumentos\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f2ca5-665f-4808-9bb0-ec212e033fd7",
   "metadata": {},
   "source": [
    "## Realizar predicciones\n",
    "\n",
    "Vamos a utilizar la $\\Theta$, el resultado de nuestro proceso de entrenamiento del modelo, para realizar predicciones sobre nuevos ejemplos que llegaran en el futuro.\n",
    "\n",
    "Generaremos un nuevo conjunto de datos X siguiendo los mismos pasos que hemos seguido anteriormente. Por tanto, si X tiene el mismo nº de características (n + 1) y sus valores están en el mismo rango de la X generada previamente, se comportarán igual que los datos usados para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c39c63-05a6-4c85-89e5-16187c4a59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realiza predicciones usando la theta calculada\n",
    "\n",
    "# Genera una nueva matriz X con nuevos ejemplos. Usa el mismo nº de características y el mismo rango de valores\n",
    "# aleatorios, pero un nº de ejemplos menor (p. ej., 25% del original)\n",
    "# Recuerda añadir el término bias, o una primera columna de 1s a la matriz, de tamaño m x n + 1\n",
    "X_pred = [...]\n",
    "\n",
    "# Calcula las predicciones para dichos nuevos datos\n",
    "y_pred = [...]    # Pista: de nuevo, matmul\n",
    "\n",
    "print('Predicciones:')\n",
    "print(y_pred)    # Puedes imprimir todo el vector o sólo los primeros valores, si es demasiado largo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e231f49-9179-411c-b34e-4548f3be6f01",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Para evaluar el modelo tenemos varias opciones. En este punto, vamos a hacer una evaluación más simple, rápida e informal del mismo. En siguientes módulos del curso veremos cómo evaluar nuestros modelos de una forma más formal y precisa.\n",
    "\n",
    "Vamos a hacer una evaluación gráfica, para comprobar simplemente que nuestra implementación funciona como esperamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33bd75-c4a1-41b1-b363-d91333bacb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Representa gráficamente los residuos entre la Y inicial y la Y predicha para los mismos ejemplos\n",
    "\n",
    "# Realiza predicciones para cada valor de la X original con la theta entrenada por el modelo\n",
    "Y_pred = [...]\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.title('Dataset original y predicciones')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Residuos')\n",
    "\n",
    "# Calcula los residuos para cada ejemplo\n",
    "# Recuerda que son la diferencia en valor absoluto entre la Y real y la Y predicha para cada ejemplo\n",
    "residuos = [...]\n",
    "\n",
    "# Usa una gráfica con series diferentes: Y de entrenamiento, Y predicha y residuos\n",
    "# Usa una gráfica de puntos para la Y de entrenamiento, de línea para la Y predicha y de barra para los residuos, superpuestas\n",
    "plt.scatter([...])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807967f-7d35-456b-8cf7-a76e25bbc041",
   "metadata": {},
   "source": [
    "Si nuestra implementación es correcta, nuestro modelo debe haber podido entrenarse correctamente y tener unos resíduos prácticamente nulos, una diferencia prácticamente nula entre los resultados originales (Y) y los resultados que calcularía nuestro modelo.\n",
    "\n",
    "Sin embargo, como recordamos, en el primer punto hemos creado un dataset con el término de error a 0. Por tanto, cada valor de Y no tiene ninguna diferencia o variación aleatoria sobre su valor real.\n",
    "\n",
    "En la vida real, sea porque no hemos tenido en cuenta todas las características que afectarían a nuestra variable objetivo, sea porque los datos contienen algún pequeño error, o sea porque, por lo general, los datos no siguen un comportamiento completamente preciso, siempre tendremos algún término de error, más o menos aleatorio.\n",
    "\n",
    "Por tanto, *¿y si vuelves a la primera celda y modificas tu término de error, y ejecutas de nuevo las siguientes para entrenar y evaluar un nuevo modelo de regresión lineal sobre datos más parecidos a la realidad?*\n",
    "\n",
    "Comprueba de dicha forma la robustez de tu implementación."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
